{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c738b72d",
   "metadata": {},
   "source": [
    "# Implementación Naive Bayes y Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e097a09",
   "metadata": {},
   "source": [
    "## Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfeb7844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los imports cargados correctamente\n"
     ]
    }
   ],
   "source": [
    "# Imports básicos\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (classification_report, precision_recall_fscore_support, \n",
    "                            confusion_matrix, accuracy_score)\n",
    "\n",
    "print(\"Todos los imports cargados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f57fe22",
   "metadata": {},
   "source": [
    "Para el split de los datos se definieron los porcentajes de acorde a lo establecido por el enunciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3333a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración establecida\n",
      "   - Test size: 30.0%\n",
      "   - Validation size: 10.0%\n",
      "   - Training size: 60.0%\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(r\"Datasets/20news-18828/20news-18828/\")  # AJUSTAR SEGÚN TU SISTEMA\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.30           # 30% para test\n",
    "VAL_RATIO_WITHIN_TRAINVAL = 1.0 / 7.0  # 10% absoluto para validación (de 70% restante)\n",
    "USE_ENGLISH_STOPWORDS = True\n",
    "\n",
    "print(\"Configuración establecida\")\n",
    "print(f\"   - Test size: {TEST_SIZE*100}%\")\n",
    "print(f\"   - Validation size: {VAL_RATIO_WITHIN_TRAINVAL * (1-TEST_SIZE) * 100:.1f}%\")\n",
    "print(f\"   - Training size: {(1-TEST_SIZE) * (1-VAL_RATIO_WITHIN_TRAINVAL) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c603f",
   "metadata": {},
   "source": [
    "## Carga de datos y train_val_test script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6428e4b",
   "metadata": {},
   "source": [
    "### 20News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b1269",
   "metadata": {},
   "source": [
    "Se cargan los datos utilizando el encoding latin-1 para no tener problemas de codificación para algunos de los caracteres presentes en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710e2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_dataset(dataroot: Path):\n",
    "    \"\"\"\n",
    "    Carga el dataset 20newsgroups desde archivos organizados en subcarpetas.\n",
    "    \"\"\"\n",
    "    dataset = load_files(\n",
    "        container_path=str(dataroot),\n",
    "        encoding=\"latin-1\",\n",
    "        decode_error=\"ignore\",\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a10a02",
   "metadata": {},
   "source": [
    "Se realiza la partición de los datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b61037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partir_train_val_test(X, y, test_size: float, val_ratio_within_trainval: float, random_state: int):\n",
    "    \"\"\"\n",
    "    Crea partición 60/10/30 estratificada.\n",
    "    \"\"\"\n",
    "    # Primero: (train+val)=70% y test=30%\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Luego: dentro del 70%, separa val=10% absoluto y train=60% absoluto\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_trainval, y_trainval,\n",
    "        test_size=val_ratio_within_trainval,\n",
    "        random_state=random_state,\n",
    "        stratify=y_trainval\n",
    "    )\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45812e20",
   "metadata": {},
   "source": [
    "Se construyó una función que permitiera construir un vectorizador que permitiera devolver el vectorizador a utilizar basado en un parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450b57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_vectorizador(kind: str, use_english_stopwords: bool, optimized=True):\n",
    "    \"\"\"\n",
    "    Construye vectorizador con parámetros optimizados o básicos.\n",
    "    \"\"\"\n",
    "    stop_words = \"english\" if use_english_stopwords else None\n",
    "    \n",
    "    if optimized:\n",
    "        # Parámetros menos restrictivos para mejor rendimiento\n",
    "        min_df = 2\n",
    "        max_df = 0.95\n",
    "        max_features = 50000\n",
    "    else:\n",
    "        # Parámetros más restrictivos para velocidad\n",
    "        min_df = 5\n",
    "        max_df = 0.90\n",
    "        max_features = 20000\n",
    "    \n",
    "    if kind == \"tf\":\n",
    "        return CountVectorizer(\n",
    "            stop_words=stop_words,\n",
    "            min_df=min_df,\n",
    "            max_df=max_df,\n",
    "            max_features=max_features\n",
    "        )\n",
    "    elif kind == \"tfidf\":\n",
    "        return TfidfVectorizer(\n",
    "            stop_words=stop_words,\n",
    "            min_df=min_df,\n",
    "            max_df=max_df,\n",
    "            max_features=max_features\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"kind debe ser 'tf' o 'tfidf'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b890b",
   "metadata": {},
   "source": [
    "Para la evaluación se realizó una función que realiza las siguientes acciones:\n",
    "\n",
    "1. Entrena utilizando únicamente el dataset de train y se evalúa con el conjunto de validación.\n",
    "2. Luego de haber calculado estas métricas se reentrena el modelo pero esta vez utilizando ambos conjuntos de datos (entrenamiento y validación).\n",
    "3. Este nuevo modelo se evalúa contra el dataset de test y se vuelve a calcular métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo_simple(pipeline, X_train, y_train, X_val, y_val, X_test, y_test, \n",
    "                         nombre_modelo, target_names, mostrar_detalles=True):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo en validación y test.\n",
    "    \"\"\"\n",
    "    # Entrenar solo en train\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar en validación\n",
    "    y_pred_val = pipeline.predict(X_val)\n",
    "    acc_val = accuracy_score(y_val, y_pred_val)\n",
    "    p_mac_val, r_mac_val, f1_mac_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average=\"macro\")\n",
    "    p_mic_val, r_mic_val, f1_mic_val, _ = precision_recall_fscore_support(y_val, y_pred_val, average=\"micro\")\n",
    "    \n",
    "    # Re-entrenar con train+val para test\n",
    "    X_train_full = np.concatenate([X_train, X_val])\n",
    "    y_train_full = np.concatenate([y_train, y_val])\n",
    "    pipeline.fit(X_train_full, y_train_full)\n",
    "    \n",
    "    # Evaluar en test\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    p_mac_test, r_mac_test, f1_mac_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average=\"macro\")\n",
    "    p_mic_test, r_mic_test, f1_mic_test, _ = precision_recall_fscore_support(y_test, y_pred_test, average=\"micro\")\n",
    "    \n",
    "    if mostrar_detalles:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"MODELO: {nombre_modelo}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(\"\\n VALIDACIÓN:\")\n",
    "        print(f\"   Accuracy: {acc_val:.4f}\")\n",
    "        print(f\"   Macro  -> P: {p_mac_val:.4f}  R: {r_mac_val:.4f}  F1: {f1_mac_val:.4f}\")\n",
    "        print(f\"   Micro  -> P: {p_mic_val:.4f}  R: {r_mic_val:.4f}  F1: {f1_mic_val:.4f}\")\n",
    "        \n",
    "        print(\"\\n TEST:\")\n",
    "        print(f\"   Accuracy: {acc_test:.4f}\")\n",
    "        print(f\"   Macro  -> P: {p_mac_test:.4f}  R: {r_mac_test:.4f}  F1: {f1_mac_test:.4f}\")\n",
    "        print(f\"   Micro  -> P: {p_mic_test:.4f}  R: {r_mic_test:.4f}  F1: {f1_mic_test:.4f}\")\n",
    "        \n",
    "        print(\"\\n Classification Report (Test):\")\n",
    "        print(classification_report(y_test, y_pred_test, target_names=target_names, digits=3))\n",
    "    \n",
    "    return {\n",
    "        'val_accuracy': acc_val, 'val_f1_macro': f1_mac_val, 'val_f1_micro': f1_mic_val,\n",
    "        'test_accuracy': acc_test, 'test_f1_macro': f1_mac_test, 'test_f1_micro': f1_mic_test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77a96f",
   "metadata": {},
   "source": [
    "## Ejecución de la carga, ejecución y evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44eed1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cargando dataset 20newsgroups...\n",
      " Dataset cargado:\n",
      "   - Total documentos: 18,828\n",
      "   - Número de clases: 20\n",
      "   - Primeras 5 clases: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n"
     ]
    }
   ],
   "source": [
    "print(\" Cargando dataset 20newsgroups...\")\n",
    "dataset = cargar_dataset(DATA_DIR)\n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "target_names = dataset.target_names\n",
    "\n",
    "print(f\" Dataset cargado:\")\n",
    "print(f\"   - Total documentos: {len(X):,}\")\n",
    "print(f\"   - Número de clases: {len(target_names)}\")\n",
    "print(f\"   - Primeras 5 clases: {target_names[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5bce57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creando particiones de datos...\n",
      " Particiones creadas:\n",
      "   - Train: 11,296 documentos (60.0%)\n",
      "   - Val:   1,883 documentos (10.0%)\n",
      "   - Test:  5,649 documentos (30.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Creando particiones de datos...\")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = partir_train_val_test(\n",
    "    X, y, TEST_SIZE, VAL_RATIO_WITHIN_TRAINVAL, RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\" Particiones creadas:\")\n",
    "print(f\"   - Train: {len(X_train):,} documentos ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   - Val:   {len(X_val):,} documentos ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"   - Test:  {len(X_test):,} documentos ({len(X_test)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30487581",
   "metadata": {},
   "source": [
    "### Construcción de los pipelines de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486eccfa",
   "metadata": {},
   "source": [
    "Una vez se han definido todas lasfunciones requeridas para este entrenamiento el siguiente paso es definir los pipelines para realizar los entrenamientos para todas las combinaciones necesarias entre los modelos de clasificación y el vectorizador a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304a31a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "I. COMPARACIÓN DE CLASIFICADORES NB Y LR\n",
      "================================================================================\n",
      "\n",
      " Entrenando modelos con representaciones TF y TF-IDF...\n",
      "\n",
      "  Entrenando NB + TF...\n",
      "\n",
      "================================================================================\n",
      "MODELO: NB + TF\n",
      "================================================================================\n",
      "\n",
      " VALIDACIÓN:\n",
      "   Accuracy: 0.8640\n",
      "   Macro  -> P: 0.8813  R: 0.8617  F1: 0.8485\n",
      "   Micro  -> P: 0.8640  R: 0.8640  F1: 0.8640\n",
      "\n",
      " TEST:\n",
      "   Accuracy: 0.8727\n",
      "   Macro  -> P: 0.8833  R: 0.8694  F1: 0.8610\n",
      "   Micro  -> P: 0.8727  R: 0.8727  F1: 0.8727\n",
      "\n",
      " Classification Report (Test):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.875     0.938     0.905       240\n",
      "           comp.graphics      0.700     0.856     0.770       292\n",
      " comp.os.ms-windows.misc      0.902     0.186     0.308       296\n",
      "comp.sys.ibm.pc.hardware      0.638     0.861     0.733       295\n",
      "   comp.sys.mac.hardware      0.831     0.906     0.867       288\n",
      "          comp.windows.x      0.743     0.915     0.820       294\n",
      "            misc.forsale      0.881     0.812     0.845       292\n",
      "               rec.autos      0.922     0.916     0.919       297\n",
      "         rec.motorcycles      0.960     0.960     0.960       298\n",
      "      rec.sport.baseball      0.973     0.973     0.973       298\n",
      "        rec.sport.hockey      0.973     0.957     0.965       300\n",
      "               sci.crypt      0.946     0.943     0.944       297\n",
      "         sci.electronics      0.866     0.878     0.872       294\n",
      "                 sci.med      0.966     0.956     0.961       297\n",
      "               sci.space      0.952     0.946     0.949       296\n",
      "  soc.religion.christian      0.884     0.943     0.913       299\n",
      "      talk.politics.guns      0.875     0.945     0.908       273\n",
      "   talk.politics.mideast      0.968     0.975     0.972       282\n",
      "      talk.politics.misc      0.875     0.901     0.888       233\n",
      "      talk.religion.misc      0.936     0.622     0.748       188\n",
      "\n",
      "                accuracy                          0.873      5649\n",
      "               macro avg      0.883     0.869     0.861      5649\n",
      "            weighted avg      0.883     0.873     0.862      5649\n",
      "\n",
      "\n",
      "  Entrenando NB + TF-IDF...\n",
      "\n",
      "================================================================================\n",
      "MODELO: NB + TF-IDF\n",
      "================================================================================\n",
      "\n",
      " VALIDACIÓN:\n",
      "   Accuracy: 0.8901\n",
      "   Macro  -> P: 0.8979  R: 0.8784  F1: 0.8786\n",
      "   Micro  -> P: 0.8901  R: 0.8901  F1: 0.8901\n",
      "\n",
      " TEST:\n",
      "   Accuracy: 0.8911\n",
      "   Macro  -> P: 0.9010  R: 0.8799  F1: 0.8801\n",
      "   Micro  -> P: 0.8911  R: 0.8911  F1: 0.8911\n",
      "\n",
      " Classification Report (Test):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.909     0.875     0.892       240\n",
      "           comp.graphics      0.828     0.825     0.827       292\n",
      " comp.os.ms-windows.misc      0.824     0.851     0.837       296\n",
      "comp.sys.ibm.pc.hardware      0.757     0.844     0.798       295\n",
      "   comp.sys.mac.hardware      0.912     0.896     0.904       288\n",
      "          comp.windows.x      0.934     0.908     0.921       294\n",
      "            misc.forsale      0.891     0.808     0.847       292\n",
      "               rec.autos      0.922     0.916     0.919       297\n",
      "         rec.motorcycles      0.957     0.970     0.963       298\n",
      "      rec.sport.baseball      0.977     0.983     0.980       298\n",
      "        rec.sport.hockey      0.967     0.977     0.972       300\n",
      "               sci.crypt      0.905     0.966     0.935       297\n",
      "         sci.electronics      0.909     0.847     0.877       294\n",
      "                 sci.med      0.965     0.939     0.952       297\n",
      "               sci.space      0.938     0.963     0.950       296\n",
      "  soc.religion.christian      0.729     0.963     0.830       299\n",
      "      talk.politics.guns      0.801     0.971     0.877       273\n",
      "   talk.politics.mideast      0.930     0.986     0.957       282\n",
      "      talk.politics.misc      0.968     0.768     0.856       233\n",
      "      talk.religion.misc      1.000     0.340     0.508       188\n",
      "\n",
      "                accuracy                          0.891      5649\n",
      "               macro avg      0.901     0.880     0.880      5649\n",
      "            weighted avg      0.899     0.891     0.887      5649\n",
      "\n",
      "\n",
      "  Entrenando LR + TF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODELO: LR + TF\n",
      "================================================================================\n",
      "\n",
      " VALIDACIÓN:\n",
      "   Accuracy: 0.9028\n",
      "   Macro  -> P: 0.9055  R: 0.9015  F1: 0.9028\n",
      "   Micro  -> P: 0.9028  R: 0.9028  F1: 0.9028\n",
      "\n",
      " TEST:\n",
      "   Accuracy: 0.8986\n",
      "   Macro  -> P: 0.8990  R: 0.8960  F1: 0.8971\n",
      "   Micro  -> P: 0.8986  R: 0.8986  F1: 0.8986\n",
      "\n",
      " Classification Report (Test):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.903     0.896     0.900       240\n",
      "           comp.graphics      0.818     0.849     0.834       292\n",
      " comp.os.ms-windows.misc      0.838     0.841     0.840       296\n",
      "comp.sys.ibm.pc.hardware      0.787     0.776     0.782       295\n",
      "   comp.sys.mac.hardware      0.846     0.896     0.870       288\n",
      "          comp.windows.x      0.866     0.857     0.862       294\n",
      "            misc.forsale      0.821     0.880     0.850       292\n",
      "               rec.autos      0.913     0.919     0.916       297\n",
      "         rec.motorcycles      0.950     0.956     0.953       298\n",
      "      rec.sport.baseball      0.950     0.950     0.950       298\n",
      "        rec.sport.hockey      0.964     0.973     0.968       300\n",
      "               sci.crypt      0.965     0.936     0.950       297\n",
      "         sci.electronics      0.859     0.847     0.853       294\n",
      "                 sci.med      0.940     0.946     0.943       297\n",
      "               sci.space      0.962     0.932     0.947       296\n",
      "  soc.religion.christian      0.911     0.923     0.917       299\n",
      "      talk.politics.guns      0.920     0.927     0.923       273\n",
      "   talk.politics.mideast      0.965     0.965     0.965       282\n",
      "      talk.politics.misc      0.924     0.884     0.904       233\n",
      "      talk.religion.misc      0.878     0.766     0.818       188\n",
      "\n",
      "                accuracy                          0.899      5649\n",
      "               macro avg      0.899     0.896     0.897      5649\n",
      "            weighted avg      0.899     0.899     0.899      5649\n",
      "\n",
      "\n",
      "  Entrenando LR + TF-IDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODELO: LR + TF-IDF\n",
      "================================================================================\n",
      "\n",
      " VALIDACIÓN:\n",
      "   Accuracy: 0.8996\n",
      "   Macro  -> P: 0.9006  R: 0.8944  F1: 0.8958\n",
      "   Micro  -> P: 0.8996  R: 0.8996  F1: 0.8996\n",
      "\n",
      " TEST:\n",
      "   Accuracy: 0.8940\n",
      "   Macro  -> P: 0.8963  R: 0.8878  F1: 0.8897\n",
      "   Micro  -> P: 0.8940  R: 0.8940  F1: 0.8940\n",
      "\n",
      " Classification Report (Test):\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.887     0.879     0.883       240\n",
      "           comp.graphics      0.790     0.839     0.814       292\n",
      " comp.os.ms-windows.misc      0.821     0.865     0.842       296\n",
      "comp.sys.ibm.pc.hardware      0.799     0.769     0.784       295\n",
      "   comp.sys.mac.hardware      0.896     0.899     0.898       288\n",
      "          comp.windows.x      0.891     0.888     0.889       294\n",
      "            misc.forsale      0.823     0.873     0.847       292\n",
      "               rec.autos      0.895     0.919     0.907       297\n",
      "         rec.motorcycles      0.962     0.940     0.951       298\n",
      "      rec.sport.baseball      0.960     0.973     0.967       298\n",
      "        rec.sport.hockey      0.967     0.963     0.965       300\n",
      "               sci.crypt      0.982     0.923     0.951       297\n",
      "         sci.electronics      0.849     0.861     0.855       294\n",
      "                 sci.med      0.910     0.953     0.931       297\n",
      "               sci.space      0.943     0.946     0.944       296\n",
      "  soc.religion.christian      0.838     0.933     0.883       299\n",
      "      talk.politics.guns      0.904     0.927     0.915       273\n",
      "   talk.politics.mideast      0.961     0.965     0.963       282\n",
      "      talk.politics.misc      0.926     0.863     0.893       233\n",
      "      talk.religion.misc      0.924     0.580     0.712       188\n",
      "\n",
      "                accuracy                          0.894      5649\n",
      "               macro avg      0.896     0.888     0.890      5649\n",
      "            weighted avg      0.896     0.894     0.893      5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"I. COMPARACIÓN DE CLASIFICADORES NB Y LR\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(\"\\n Entrenando modelos con representaciones TF y TF-IDF...\")\n",
    "\n",
    "# Crear pipelines\n",
    "pipelines = {\n",
    "    \"NB + TF\": Pipeline([\n",
    "        (\"vec\", construir_vectorizador(\"tf\", USE_ENGLISH_STOPWORDS, optimized=True)),\n",
    "        (\"clf\", MultinomialNB())\n",
    "    ]),\n",
    "    \"NB + TF-IDF\": Pipeline([\n",
    "        (\"vec\", construir_vectorizador(\"tfidf\", USE_ENGLISH_STOPWORDS, optimized=True)),\n",
    "        (\"clf\", MultinomialNB())\n",
    "    ]),\n",
    "    \"LR + TF\": Pipeline([\n",
    "        (\"vec\", construir_vectorizador(\"tf\", USE_ENGLISH_STOPWORDS, optimized=True)),\n",
    "        (\"clf\", LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\", random_state=RANDOM_STATE, max_iter=2000))\n",
    "    ]),\n",
    "    \"LR + TF-IDF\": Pipeline([\n",
    "        (\"vec\", construir_vectorizador(\"tfidf\", USE_ENGLISH_STOPWORDS, optimized=True)),\n",
    "        (\"clf\", LogisticRegression(solver=\"liblinear\", multi_class=\"ovr\", random_state=RANDOM_STATE, max_iter=2000))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Evaluar cada pipeline\n",
    "resultados_parte1 = {}\n",
    "for nombre, pipeline in pipelines.items():\n",
    "    print(f\"\\n  Entrenando {nombre}...\")\n",
    "    resultado = evaluar_modelo_simple(\n",
    "        pipeline, X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        nombre, target_names, mostrar_detalles=True\n",
    "    )\n",
    "    resultados_parte1[nombre] = resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70d2ec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " RESUMEN PARTE I - COMPARACIÓN INICIAL\n",
      "================================================================================\n",
      "\n",
      " Métricas en TEST:\n",
      "             test_accuracy  test_f1_macro  test_f1_micro\n",
      "NB + TF             0.8727         0.8610         0.8727\n",
      "NB + TF-IDF         0.8911         0.8801         0.8911\n",
      "LR + TF             0.8986         0.8971         0.8986\n",
      "LR + TF-IDF         0.8940         0.8897         0.8940\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\" RESUMEN PARTE I - COMPARACIÓN INICIAL\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "df_parte1 = pd.DataFrame(resultados_parte1).T\n",
    "print(\"\\n Métricas en TEST:\")\n",
    "print(df_parte1[['test_accuracy', 'test_f1_macro', 'test_f1_micro']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7812119",
   "metadata": {},
   "source": [
    "De la tabla anterior se observa que LR + TF obtiene el mejor desempeño global en todas las métricas. Sin embargo, LR + TF-IDF también presenta unas métricas bastante buenas y cercanas al mejor modelo.\n",
    "\n",
    "También es posible notar que parece ser que el uso de TF-IDF presenta un impacto positivo especialmente para Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da22bc9",
   "metadata": {},
   "source": [
    "### Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd29079",
   "metadata": {},
   "source": [
    "#### Cross validation Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e4333",
   "metadata": {},
   "source": [
    "En este experimento se implementa un proceso de validación cruzada de diez pliegues. El procedimiento consiste en construir dos configuraciones de *pipeline* que difieren únicamente en el tipo de representación vectorial utilizada para los documentos (frecuencias absolutas de términos y frecuencias ponderadas mediante TF-IDF) y medir su rendimiento de forma consistente a través de múltiples métricas de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6379fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "II. INVESTIGACIÓN DE VALIDACIÓN CRUZADA\n",
      "================================================================================\n",
      "\n",
      " Preparando validación cruzada con train+validation...\n",
      "   - Datos para CV: 13,179 documentos\n",
      "\n",
      "============================================================\n",
      " VALIDACIÓN CRUZADA - NAIVE BAYES\n",
      "============================================================\n",
      "\n",
      "  Evaluando NB + TF...\n",
      " Resultados NB + TF (10-fold CV):\n",
      "   accuracy       : 0.8582 ± 0.0095\n",
      "   precision_macro: 0.8738 ± 0.0090\n",
      "   recall_macro   : 0.8554 ± 0.0091\n",
      "   f1_macro       : 0.8434 ± 0.0098\n",
      "   precision_micro: 0.8582 ± 0.0095\n",
      "   recall_micro   : 0.8582 ± 0.0095\n",
      "   f1_micro       : 0.8582 ± 0.0095\n",
      "\n",
      "  Evaluando NB + TF-IDF...\n",
      " Resultados NB + TF-IDF (10-fold CV):\n",
      "   accuracy       : 0.8799 ± 0.0066\n",
      "   precision_macro: 0.8898 ± 0.0071\n",
      "   recall_macro   : 0.8684 ± 0.0068\n",
      "   f1_macro       : 0.8680 ± 0.0074\n",
      "   precision_micro: 0.8799 ± 0.0066\n",
      "   recall_micro   : 0.8799 ± 0.0066\n",
      "   f1_micro       : 0.8799 ± 0.0066\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"II. INVESTIGACIÓN DE VALIDACIÓN CRUZADA\")\n",
    "print(f\"{'='*80}\")\n",
    "print(\"\\n Preparando validación cruzada con train+validation...\")\n",
    "X_trainval = list(X_train) + list(X_val)\n",
    "y_trainval = list(y_train) + list(y_val)\n",
    "\n",
    "print(f\"   - Datos para CV: {len(X_trainval):,} documentos\")\n",
    "\n",
    "# Configurar CV\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "scoring_metrics = [\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \n",
    "                  \"precision_micro\", \"recall_micro\", \"f1_micro\"]\n",
    "\n",
    "# CV para Naive Bayes\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" VALIDACIÓN CRUZADA - NAIVE BAYES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "nb_results = {}\n",
    "for vectorizer_name, vectorizer_type in [(\"TF\", \"tf\"), (\"TF-IDF\", \"tfidf\")]:\n",
    "    print(f\"\\n  Evaluando NB + {vectorizer_name}...\")\n",
    "    \n",
    "    pipeline_nb = Pipeline([\n",
    "        (\"vec\", construir_vectorizador(vectorizer_type, USE_ENGLISH_STOPWORDS, optimized=False)),\n",
    "        (\"clf\", MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    cv_results = cross_validate(\n",
    "        pipeline_nb, X_trainval, y_trainval,\n",
    "        cv=cv_strategy, scoring=scoring_metrics, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    nb_results[f\"NB + {vectorizer_name}\"] = cv_results\n",
    "    \n",
    "    print(f\" Resultados NB + {vectorizer_name} (10-fold CV):\")\n",
    "    for metric in scoring_metrics:\n",
    "        scores = cv_results[f\"test_{metric}\"]\n",
    "        print(f\"   {metric:15s}: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fcaf32",
   "metadata": {},
   "source": [
    "Los resultados de la validación cruzada muestran un patrón claro: el uso de representaciones TF-IDF ofrece una mejora consistente frente a las representaciones basadas únicamente en frecuencias absolutas (TF). En particular, Naive Bayes con TF-IDF alcanza un *accuracy* promedio cercano al 88% con una desviación estándar baja, lo que refleja tanto un mejor rendimiento como una mayor estabilidad entre los pliegues. Además, las métricas macro (precisión, recall y F1) son superiores en este esquema, lo que indica un tratamiento más equilibrado de las diferentes clases. En contraste, el modelo con TF presenta un rendimiento aceptable pero con un sesgo más marcado, evidenciado en un F1 macro más bajo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2448cd8",
   "metadata": {},
   "source": [
    "#### Cross validation Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91013d5d",
   "metadata": {},
   "source": [
    "En este caso se lleva a cabo una búsqueda sistemática de hiperparámetros para modelos de regresión logística aplicados a clasificación de texto. El procedimiento consiste en integrar un *pipeline* con dos variantes de vectorización (TF y TF-IDF) y un clasificador de regresión logística, sobre el cual se exploran combinaciones de hiperparámetros clave: el coeficiente de regularización (*C*), el tipo de penalización (*l1* o *l2*) y el solucionador (*liblinear*, compatible con ambas penalizaciones). Para cada configuración se ejecuta una búsqueda en malla (*Grid Search*) con validación cruzada  de diez pliegues, utilizando como métrica principal el F1 macro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36754b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BÚSQUEDA DE HIPERPARÁMETROS - LOGISTIC REGRESSION\n",
      "============================================================\n",
      "\n",
      " Búsqueda de hiperparámetros LR + TF...\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mejores parámetros LR + TF:\n",
      "   clf__C: 0.5\n",
      "   clf__penalty: l2\n",
      "   clf__solver: liblinear\n",
      "   Mejor F1-macro CV: 0.8927\n",
      "📊 Resultados LR + TF (mejor modelo, 10-fold CV):\n",
      "   accuracy       : 0.8941 ± 0.0082\n",
      "   precision_macro: 0.8963 ± 0.0083\n",
      "   recall_macro   : 0.8915 ± 0.0084\n",
      "   f1_macro       : 0.8927 ± 0.0084\n",
      "   precision_micro: 0.8941 ± 0.0082\n",
      "   recall_micro   : 0.8941 ± 0.0082\n",
      "   f1_micro       : 0.8941 ± 0.0082\n",
      "\n",
      " Búsqueda de hiperparámetros LR + TF-IDF...\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mejores parámetros LR + TF-IDF:\n",
      "   clf__C: 5.0\n",
      "   clf__penalty: l2\n",
      "   clf__solver: liblinear\n",
      "   Mejor F1-macro CV: 0.9084\n",
      "📊 Resultados LR + TF-IDF (mejor modelo, 10-fold CV):\n",
      "   accuracy       : 0.9105 ± 0.0062\n",
      "   precision_macro: 0.9118 ± 0.0063\n",
      "   recall_macro   : 0.9071 ± 0.0065\n",
      "   f1_macro       : 0.9084 ± 0.0064\n",
      "   precision_micro: 0.9105 ± 0.0062\n",
      "   recall_micro   : 0.9105 ± 0.0062\n",
      "   f1_micro       : 0.9105 ± 0.0062\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BÚSQUEDA DE HIPERPARÁMETROS - LOGISTIC REGRESSION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Parámetros más amplios pero computacionalmente factibles\n",
    "param_grid_lr = {\n",
    "    'clf__C': [0.1, 0.5, 1.0, 2.0, 5.0],  # Regularización\n",
    "    'clf__penalty': ['l1', 'l2'],          # Tipo de regularización\n",
    "    'clf__solver': ['liblinear']            # Solver compatible con l1 y l2\n",
    "}\n",
    "\n",
    "lr_results = {}\n",
    "for vectorizer_name, vectorizer_type in [(\"TF\", \"tf\"), (\"TF-IDF\", \"tfidf\")]:\n",
    "    print(f\"\\n Búsqueda de hiperparámetros LR + {vectorizer_name}...\")\n",
    "    \n",
    "    pipeline_lr = Pipeline([\n",
    "        (\"vec\", construir_vectorizador(vectorizer_type, USE_ENGLISH_STOPWORDS, optimized=False)),\n",
    "        (\"clf\", LogisticRegression(multi_class=\"ovr\", random_state=RANDOM_STATE, max_iter=3000))\n",
    "    ])\n",
    "    \n",
    "    # GridSearch con CV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline_lr, param_grid_lr,\n",
    "        cv=cv_strategy, scoring='f1_macro',\n",
    "        n_jobs=-1, verbose=1, refit=True\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # Mejores parámetros\n",
    "    print(f\" Mejores parámetros LR + {vectorizer_name}:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"   {param}: {value}\")\n",
    "    print(f\"   Mejor F1-macro CV: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Evaluación completa del mejor modelo\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "    cv_results_best = cross_validate(\n",
    "        best_pipeline, X_trainval, y_trainval,\n",
    "        cv=cv_strategy, scoring=scoring_metrics, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    lr_results[f\"LR + {vectorizer_name}\"] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'cv_results': cv_results_best,\n",
    "        'best_pipeline': best_pipeline\n",
    "    }\n",
    "    \n",
    "    print(f\"📊 Resultados LR + {vectorizer_name} (mejor modelo, 10-fold CV):\")\n",
    "    for metric in scoring_metrics:\n",
    "        scores = cv_results_best[f\"test_{metric}\"]\n",
    "        print(f\"   {metric:15s}: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41949373",
   "metadata": {},
   "source": [
    "Los resultados obtenidos muestran que la combinación de regresión logística con representación TF-IDF ofrece un desempeño muy sólido y balanceado en la tarea de clasificación. El mejor modelo, configurado con __regularización L2__ y un coeficiente de regularización de __5.0__, alcanza un F1-macro promedio de __0.9084__ en validación cruzada, lo que indica un buen equilibrio entre precisión y exhaustividad en todas las clases. Además, la consistencia de las métricas —con desviaciones estándar muy bajas en torno a 0.006— refleja una alta estabilidad del modelo frente a las distintas particiones de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57696444",
   "metadata": {},
   "source": [
    "#### Resumen de la validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaef28bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " RESUMEN VALIDACIÓN CRUZADA (10-fold)\n",
      "================================================================================\n",
      "                    F1 Macro         F1 Micro         Accuracy\n",
      "NB + TF      0.8434 ± 0.0098  0.8582 ± 0.0095  0.8582 ± 0.0095\n",
      "NB + TF-IDF  0.8680 ± 0.0074  0.8799 ± 0.0066  0.8799 ± 0.0066\n",
      "LR + TF      0.8927 ± 0.0084  0.8941 ± 0.0082  0.8941 ± 0.0082\n",
      "LR + TF-IDF  0.9084 ± 0.0064  0.9105 ± 0.0062  0.9105 ± 0.0062\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\" RESUMEN VALIDACIÓN CRUZADA (10-fold)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "cv_summary = {}\n",
    "for model_name, results in nb_results.items():\n",
    "    cv_summary[model_name] = {\n",
    "        'F1 Macro': f\"{np.mean(results['test_f1_macro']):.4f} ± {np.std(results['test_f1_macro']):.4f}\",\n",
    "        'F1 Micro': f\"{np.mean(results['test_f1_micro']):.4f} ± {np.std(results['test_f1_micro']):.4f}\",\n",
    "        'Accuracy': f\"{np.mean(results['test_accuracy']):.4f} ± {np.std(results['test_accuracy']):.4f}\"\n",
    "    }\n",
    "\n",
    "for model_name, results in lr_results.items():\n",
    "    cv_summary[model_name] = {\n",
    "        'F1 Macro': f\"{np.mean(results['cv_results']['test_f1_macro']):.4f} ± {np.std(results['cv_results']['test_f1_macro']):.4f}\",\n",
    "        'F1 Micro': f\"{np.mean(results['cv_results']['test_f1_micro']):.4f} ± {np.std(results['cv_results']['test_f1_micro']):.4f}\",\n",
    "        'Accuracy': f\"{np.mean(results['cv_results']['test_accuracy']):.4f} ± {np.std(results['cv_results']['test_accuracy']):.4f}\"\n",
    "    }\n",
    "\n",
    "df_cv = pd.DataFrame(cv_summary).T\n",
    "print(df_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61988d6",
   "metadata": {},
   "source": [
    "#### Evaluación de los modelos Naive Bayes enm test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c716b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "III. EVALUACIÓN FINAL EN TEST SET\n",
      "================================================================================\n",
      " Evaluando todos los modelos en el conjunto de test...\n",
      "\n",
      "  Evaluando NB + TF en test...\n",
      "   Accuracy: 0.8727 | F1-Macro: 0.8610 | F1-Micro: 0.8727\n",
      "\n",
      "  Evaluando NB + TF-IDF en test...\n",
      "   Accuracy: 0.8911 | F1-Macro: 0.8801 | F1-Micro: 0.8911\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"III. EVALUACIÓN FINAL EN TEST SET\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(\" Evaluando todos los modelos en el conjunto de test...\")\n",
    "\n",
    "# Re-entrenar modelos con train+val y evaluar en test\n",
    "final_results = {}\n",
    "\n",
    "# Naive Bayes models\n",
    "for vectorizer_name, vectorizer_type in [(\"TF\", \"tf\"), (\"TF-IDF\", \"tfidf\")]:\n",
    "    model_name = f\"NB + {vectorizer_name}\"\n",
    "    print(f\"\\n  Evaluando {model_name} en test...\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"vec\", construir_vectorizador(vectorizer_type, USE_ENGLISH_STOPWORDS, optimized=True)),\n",
    "        (\"clf\", MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_trainval, y_trainval)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")\n",
    "    p_micro, r_micro, f1_micro, _ = precision_recall_fscore_support(y_test, y_pred, average=\"micro\")\n",
    "    \n",
    "    final_results[model_name] = {\n",
    "        'Accuracy': acc, 'Precision Macro': p_macro, 'Recall Macro': r_macro, 'F1 Macro': f1_macro,\n",
    "        'Precision Micro': p_micro, 'Recall Micro': r_micro, 'F1 Micro': f1_micro\n",
    "    }\n",
    "    \n",
    "    print(f\"   Accuracy: {acc:.4f} | F1-Macro: {f1_macro:.4f} | F1-Micro: {f1_micro:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31cdb2",
   "metadata": {},
   "source": [
    "#### Evaluación de los modelos de regresión logística con mejores hiperparámetros en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4c9ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Evaluando LR + TF en test (mejores hiperparámetros)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.8915 | F1-Macro: 0.8898 | F1-Micro: 0.8915\n",
      "   Mejores parámetros: {'clf__C': 0.5, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "\n",
      "  Evaluando LR + TF-IDF en test (mejores hiperparámetros)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\ir-gensim\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy: 0.9106 | F1-Macro: 0.9087 | F1-Micro: 0.9106\n",
      "   Mejores parámetros: {'clf__C': 5.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "for vectorizer_name in [\"TF\", \"TF-IDF\"]:\n",
    "    model_name = f\"LR + {vectorizer_name}\"\n",
    "    print(f\"\\n  Evaluando {model_name} en test (mejores hiperparámetros)...\")\n",
    "    \n",
    "    best_pipeline = lr_results[model_name]['best_pipeline']\n",
    "    best_pipeline.fit(X_trainval, y_trainval)\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    p_macro, r_macro, f1_macro, _ = precision_recall_fscore_support(y_test, y_pred, average=\"macro\")\n",
    "    p_micro, r_micro, f1_micro, _ = precision_recall_fscore_support(y_test, y_pred, average=\"micro\")\n",
    "    \n",
    "    final_results[model_name] = {\n",
    "        'Accuracy': acc, 'Precision Macro': p_macro, 'Recall Macro': r_macro, 'F1 Macro': f1_macro,\n",
    "        'Precision Micro': p_micro, 'Recall Micro': r_micro, 'F1 Micro': f1_micro\n",
    "    }\n",
    "    \n",
    "    print(f\"   Accuracy: {acc:.4f} | F1-Macro: {f1_macro:.4f} | F1-Micro: {f1_micro:.4f}\")\n",
    "    print(f\"   Mejores parámetros: {lr_results[model_name]['best_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc59fb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " RESULTADOS FINALES EN TEST SET\n",
      "================================================================================\n",
      "\n",
      " Métricas de rendimiento:\n",
      "             Accuracy  Precision Macro  Recall Macro  F1 Macro  \\\n",
      "NB + TF        0.8727           0.8833        0.8694    0.8610   \n",
      "NB + TF-IDF    0.8911           0.9010        0.8799    0.8801   \n",
      "LR + TF        0.8915           0.8916        0.8887    0.8898   \n",
      "LR + TF-IDF    0.9106           0.9112        0.9074    0.9087   \n",
      "\n",
      "             Precision Micro  Recall Micro  F1 Micro  \n",
      "NB + TF               0.8727        0.8727    0.8727  \n",
      "NB + TF-IDF           0.8911        0.8911    0.8911  \n",
      "LR + TF               0.8915        0.8915    0.8915  \n",
      "LR + TF-IDF           0.9106        0.9106    0.9106  \n",
      "\n",
      " MEJORES MODELOS:\n",
      "    Mejor F1-Macro:  LR + TF-IDF (0.9087)\n",
      "    Mejor F1-Micro:  LR + TF-IDF (0.9106)\n",
      "    Mejor Accuracy:  LR + TF-IDF (0.9106)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\" RESULTADOS FINALES EN TEST SET\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "df_final = pd.DataFrame(final_results).T\n",
    "print(\"\\n Métricas de rendimiento:\")\n",
    "print(df_final.round(4))\n",
    "\n",
    "# Identificar el mejor modelo\n",
    "best_model_f1_macro = df_final['F1 Macro'].idxmax()\n",
    "best_model_f1_micro = df_final['F1 Micro'].idxmax()\n",
    "best_model_accuracy = df_final['Accuracy'].idxmax()\n",
    "\n",
    "print(f\"\\n MEJORES MODELOS:\")\n",
    "print(f\"    Mejor F1-Macro:  {best_model_f1_macro} ({df_final.loc[best_model_f1_macro, 'F1 Macro']:.4f})\")\n",
    "print(f\"    Mejor F1-Micro:  {best_model_f1_micro} ({df_final.loc[best_model_f1_micro, 'F1 Micro']:.4f})\")\n",
    "print(f\"    Mejor Accuracy:  {best_model_accuracy} ({df_final.loc[best_model_accuracy, 'Accuracy']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87d107cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " ANÁLISIS DEL MEJOR MODELO\n",
      "================================================================================\n",
      "Modelo seleccionado: LR + TF-IDF\n",
      "Representación: TF-IDF\n",
      "Hiperparámetros optimizados:\n",
      "   clf__C: 5.0\n",
      "   clf__penalty: l2\n",
      "   clf__solver: liblinear\n",
      "\n",
      "Reporte detallado del mejor modelo:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism      0.893     0.900     0.896       240\n",
      "           comp.graphics      0.816     0.863     0.839       292\n",
      " comp.os.ms-windows.misc      0.828     0.861     0.844       296\n",
      "comp.sys.ibm.pc.hardware      0.830     0.797     0.813       295\n",
      "   comp.sys.mac.hardware      0.902     0.899     0.901       288\n",
      "          comp.windows.x      0.891     0.891     0.891       294\n",
      "            misc.forsale      0.845     0.894     0.869       292\n",
      "               rec.autos      0.929     0.923     0.926       297\n",
      "         rec.motorcycles      0.973     0.956     0.964       298\n",
      "      rec.sport.baseball      0.970     0.980     0.975       298\n",
      "        rec.sport.hockey      0.973     0.970     0.972       300\n",
      "               sci.crypt      0.982     0.933     0.957       297\n",
      "         sci.electronics      0.870     0.888     0.879       294\n",
      "                 sci.med      0.931     0.953     0.942       297\n",
      "               sci.space      0.955     0.939     0.947       296\n",
      "  soc.religion.christian      0.891     0.933     0.912       299\n",
      "      talk.politics.guns      0.941     0.941     0.941       273\n",
      "   talk.politics.mideast      0.972     0.972     0.972       282\n",
      "      talk.politics.misc      0.931     0.927     0.929       233\n",
      "      talk.religion.misc      0.901     0.729     0.806       188\n",
      "\n",
      "                accuracy                          0.911      5649\n",
      "               macro avg      0.911     0.907     0.909      5649\n",
      "            weighted avg      0.911     0.911     0.911      5649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\" ANÁLISIS DEL MEJOR MODELO\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "best_overall = best_model_f1_macro  # Usar F1-macro como criterio principal\n",
    "print(f\"Modelo seleccionado: {best_overall}\")\n",
    "\n",
    "if best_overall.startswith(\"LR\"):\n",
    "    vectorizer_type = \"TF\" if \"TF-IDF\" not in best_overall else \"TF-IDF\"\n",
    "    best_params = lr_results[best_overall]['best_params']\n",
    "    print(f\"Representación: {vectorizer_type}\")\n",
    "    print(f\"Hiperparámetros optimizados:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"   {param}: {value}\")\n",
    "\n",
    "print(f\"\\nReporte detallado del mejor modelo:\")\n",
    "if best_overall.startswith(\"LR\"):\n",
    "    best_pipeline = lr_results[best_overall]['best_pipeline']\n",
    "else:\n",
    "    vectorizer_type = \"tf\" if \"TF-IDF\" not in best_overall else \"tfidf\"\n",
    "    best_pipeline = Pipeline([\n",
    "        (\"vec\", construir_vectorizador(vectorizer_type, USE_ENGLISH_STOPWORDS, optimized=True)),\n",
    "        (\"clf\", MultinomialNB())\n",
    "    ])\n",
    "    best_pipeline.fit(X_trainval, y_trainval)\n",
    "\n",
    "y_pred_best = best_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_best, target_names=target_names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb6fb6",
   "metadata": {},
   "source": [
    "Al final de toda la experimentación, el mejor modelo identificado fue la regresión logística con representación TF-IDF y regularización L2, que alcanzó un desempeño sobresaliente con una exactitud global del 91.1 %. El análisis detallado por clase muestra resultados consistentes y elevados en precisión, recall y F1, con un promedio macro de 0.911, 0.907 y 0.909, respectivamente. Se destacan categorías como *rec.sport.baseball*, *rec.motorcycles* y *talk.politics.mideast*, donde los puntajes F1 superan el 0.95, evidenciando la capacidad del modelo para distinguir con gran efectividad estos temas. Aunque algunas clases como *talk.religion.misc* presentan un rendimiento relativamente menor, el modelo mantiene en general un balance adecuado en todos los grupos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
